**Supervised machine learning** algorithms can be categorized into **Regression** and **Classification** based on the type of output they predict.

### **Regression Algorithms**  

Regression algorithms predict **continuous values** (e.g., house prices, temperature, stock prices).  
Examples:  

1. **Linear Regression**  
2. **Polynomial Regression**  
3. **Ridge Regression**  
4. **Lasso Regression**  
5. **Elastic Net Regression**  
6. **Support Vector Regression (SVR)**  
7. **Decision Tree Regression**  
8. **Random Forest Regression**  
9. **Gradient Boosting Regression (GBR)**  
10. **XGBoost Regression**  

---

### **Classification Algorithms**

Classification algorithms predict **discrete labels** or **categories** (e.g., spam vs. not spam, disease diagnosis).  
Examples:

1. **Logistic Regression** (Despite the name, it's for classification)
2. **K-Nearest Neighbors (KNN)**  
3. **Support Vector Machine (SVM)**  
4. **Decision Tree Classifier**  
5. **Random Forest Classifier**  
6. **Gradient Boosting Classifier** (e.g., XGBoost, LightGBM, CatBoost)  
7. **Na√Øve Bayes (Gaussian, Multinomial, Bernoulli)**  
8. **Artificial Neural Networks (ANNs)**  
9. **Linear Discriminant Analysis (LDA)**  
10. **Quadratic Discriminant Analysis (QDA)**  

Some algorithms (like Decision Trees, Random Forests, and Gradient Boosting) work for **both regression and classification**, depending on the problem setup.
